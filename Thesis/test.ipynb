{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: ['archive_size', 'epsilon_indicator', 'generational_distance', 'hypervolume', 'nfe', 'spacing', 'spread', 'time_efficiency']\n",
      "Hypervolume sample: [0.         0.00358065 0.22993001 0.37533905 0.43444705]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('Thesis/hpc/results/DTLZ2/4_cores/eps_nsgaii/seed42/results_DTLZ2_eps_nsgaii_4cores_seed_42.h5', 'r') as hf:\n",
    "    print(\"Metrics:\", list(hf['metrics'].keys()))\n",
    "    print(\"Hypervolume sample:\", hf['metrics/hypervolume'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: ['archive_size', 'epsilon_indicator', 'generational_distance', 'hypervolume', 'nfe', 'spacing', 'spread', 'time_efficiency']\n",
      "Hypervolume sample: [0.         0.00991249 0.25116119 0.42920934 0.50316186]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('Thesis/hpc/results/DTLZ2/4_cores/borg/seed42/results_DTLZ2_borg_4cores_seed_42.h5', 'r') as hf:\n",
    "    print(\"Metrics:\", list(hf['metrics'].keys()))\n",
    "    print(\"Hypervolume sample:\", hf['metrics/hypervolume'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hdf5_structure(group, indent=0):\n",
    "    \"\"\"Recursively prints the hierarchy of an HDF5 file.\"\"\"\n",
    "    for key in group:\n",
    "        obj = group[key]\n",
    "        print(\"  \" * indent + f\"- {key} ({'Group' if isinstance(obj, h5py.Group) else 'Dataset'})\")\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            print_hdf5_structure(obj, indent + 1)  # Recursively explore subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 File Structure:\n",
      "- convergence (Group)\n",
      "  - epsilon_progress (Dataset)\n",
      "  - nfe (Dataset)\n",
      "- metrics (Group)\n",
      "  - archive_size (Dataset)\n",
      "  - epsilon_indicator (Dataset)\n",
      "  - generational_distance (Dataset)\n",
      "  - hypervolume (Dataset)\n",
      "  - nfe (Dataset)\n",
      "  - spacing (Dataset)\n",
      "  - spread (Dataset)\n",
      "  - time_efficiency (Dataset)\n",
      "- results (Group)\n",
      "  - f0 (Dataset)\n",
      "  - f1 (Dataset)\n",
      "  - f2 (Dataset)\n",
      "  - f3 (Dataset)\n",
      "  - x0 (Dataset)\n",
      "  - x1 (Dataset)\n",
      "  - x10 (Dataset)\n",
      "  - x11 (Dataset)\n",
      "  - x12 (Dataset)\n",
      "  - x2 (Dataset)\n",
      "  - x3 (Dataset)\n",
      "  - x4 (Dataset)\n",
      "  - x5 (Dataset)\n",
      "  - x6 (Dataset)\n",
      "  - x7 (Dataset)\n",
      "  - x8 (Dataset)\n",
      "  - x9 (Dataset)\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "file_path = \"hpc/results/DTLZ2/4_cores/eps_nsgaii/seed42/results_DTLZ2_eps_nsgaii_4cores_seed_42.h5\"\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    print(\"HDF5 File Structure:\")\n",
    "    print_hdf5_structure(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of metrics/hypervolume:\n",
      "[0.         0.00358065 0.22993001 0.37533905 0.43444705 0.477809\n",
      " 0.5066171  0.53628941 0.56394265 0.58215318 0.59280392 0.59758254]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"hpc/results/DTLZ2/4_cores/eps_nsgaii/seed42/results_DTLZ2_eps_nsgaii_4cores_seed_42.h5\"\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    dataset_path = \"metrics/hypervolume\"  # Change this based on your structure\n",
    "    if dataset_path in f:\n",
    "        data = f[dataset_path][:]\n",
    "        print(f\"Contents of {dataset_path}:\")\n",
    "        print(data)\n",
    "    else:\n",
    "        print(f\"Dataset {dataset_path} not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSc_Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
